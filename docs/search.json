[
  {
    "objectID": "notebooks/02-collating-gps-data.html",
    "href": "notebooks/02-collating-gps-data.html",
    "title": "Cleaning GPS data",
    "section": "",
    "text": "Update History\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges\n\n\n\n\n2024-07-19\nRerun to add turn angles.\n\n\n2024-07-17\nInitial post.\n\n\n\nRun this code once only to make clean and aggregated GPS datasets.\n\n\n\n\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(here)\nlibrary(sf)\n\nsource(str_glue(\"{here()}/scripts/gps-data-utils.R\"))\n\n\nRead raw files, clean and write any that still have data remaining\n\nsrc_folder &lt;- str_glue(\"{here()}/_data/GPS-1516Season-MiersValley\")\ntgt_folder &lt;- str_glue(\"{here()}/_data/cleaned-gps-data\")\n\nif (!file.exists(tgt_folder)) {\n  dir.create(tgt_folder)\n}\npersons &lt;- dir(src_folder, pattern = \".csv\") |&gt;\n  lapply(str_split_i, \"-\", i = 1) |&gt;\n  unlist()\ndfs &lt;- list()\ni &lt;- 0\nfor (p in persons) {\n  i &lt;- i + 1\n  df &lt;- get_cleaned_gps_data(str_glue(\"{src_folder}/{p}-FINAL.csv\"), p) \n  if (nrow(df) &gt; 0) {\n    df |&gt; write.csv(str_glue(\"{tgt_folder}/{p}-cleaned.csv\"))\n    dfs[[i]] &lt;- df\n  }\n}\nbind_rows(dfs) |&gt;\n  write.csv(str_glue(\"{tgt_folder}/all-gps-traces.csv\"))\n\n\n\nWrite to individual GPKG files and a single all traces file\n\nfiles &lt;- str_c(tgt_folder, \"/\", dir(path = tgt_folder, pattern = \".csv\"))\nfor (f in files) {\n  get_gps_data_as_sf(f) |&gt; \n    st_write(str_replace(f, \"csv\", \"gpkg\"), delete_dsn = TRUE)\n}\n\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/all-gps-traces.gpkg' using driver `GPKG'\nWriting layer `all-gps-traces' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/all-gps-traces.gpkg' using driver `GPKG'\nWriting 112216 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/AVC-cleaned.gpkg' using driver `GPKG'\nWriting layer `AVC-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/AVC-cleaned.gpkg' using driver `GPKG'\nWriting 5069 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Ben-cleaned.gpkg' using driver `GPKG'\nWriting layer `Ben-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Ben-cleaned.gpkg' using driver `GPKG'\nWriting 6918 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Charlie-cleaned.gpkg' using driver `GPKG'\nWriting layer `Charlie-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Charlie-cleaned.gpkg' using driver `GPKG'\nWriting 5851 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Craig-cleaned.gpkg' using driver `GPKG'\nWriting layer `Craig-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Craig-cleaned.gpkg' using driver `GPKG'\nWriting 1668 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Fraser-cleaned.gpkg' using driver `GPKG'\nWriting layer `Fraser-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Fraser-cleaned.gpkg' using driver `GPKG'\nWriting 7216 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Gemma-cleaned.gpkg' using driver `GPKG'\nWriting layer `Gemma-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Gemma-cleaned.gpkg' using driver `GPKG'\nWriting 8428 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Georgia-cleaned.gpkg' using driver `GPKG'\nWriting layer `Georgia-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Georgia-cleaned.gpkg' using driver `GPKG'\nWriting 4685 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/IanHawes-cleaned.gpkg' using driver `GPKG'\nWriting layer `IanHawes-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/IanHawes-cleaned.gpkg' using driver `GPKG'\nWriting 6593 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/IanMcD-cleaned.gpkg' using driver `GPKG'\nWriting layer `IanMcD-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/IanMcD-cleaned.gpkg' using driver `GPKG'\nWriting 8861 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Jayne-cleaned.gpkg' using driver `GPKG'\nWriting layer `Jayne-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Jayne-cleaned.gpkg' using driver `GPKG'\nWriting 6448 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Kurt-cleaned.gpkg' using driver `GPKG'\nWriting layer `Kurt-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Kurt-cleaned.gpkg' using driver `GPKG'\nWriting 6178 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Marwan-cleaned.gpkg' using driver `GPKG'\nWriting layer `Marwan-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Marwan-cleaned.gpkg' using driver `GPKG'\nWriting 10385 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Paul-cleaned.gpkg' using driver `GPKG'\nWriting layer `Paul-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Paul-cleaned.gpkg' using driver `GPKG'\nWriting 7320 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Peyman-cleaned.gpkg' using driver `GPKG'\nWriting layer `Peyman-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Peyman-cleaned.gpkg' using driver `GPKG'\nWriting 8390 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Pierre-cleaned.gpkg' using driver `GPKG'\nWriting layer `Pierre-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Pierre-cleaned.gpkg' using driver `GPKG'\nWriting 8615 features with 26 fields and geometry type Point.\nDeleting source `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Tim-cleaned.gpkg' using driver `GPKG'\nWriting layer `Tim-cleaned' to data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/Tim-cleaned.gpkg' using driver `GPKG'\nWriting 9591 features with 26 fields and geometry type Point.",
    "crumbs": [
      "Notebooks",
      "Cleaning GPS data"
    ]
  },
  {
    "objectID": "notebooks/03-estimating-a-hiking-function.html",
    "href": "notebooks/03-estimating-a-hiking-function.html",
    "title": "Estimating a hiking function",
    "section": "",
    "text": "Update History\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges\n\n\n\n\n2024-07-19\nAdded nlsLM estimation of models.\n\n\n2024-07-17\nInitial post.\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(here)\nlibrary(sf)\nlibrary(terra)\nlibrary(tmap)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(minpack.lm)\nsrc_folder &lt;- str_glue(\"{here()}/_data/GPS-1516Season-MiersValley\")\ntgt_folder &lt;- str_glue(\"{here()}/_data/cleaned-gps-data\")\nall_traces &lt;- st_read(str_glue(\"{tgt_folder}/all-gps-traces.gpkg\"))\n\nReading layer `all-gps-traces' from data source \n  `/Users/david/Documents/work/mwlr-tpm-antarctica/antarctica/_data/cleaned-gps-data/all-gps-traces.gpkg' \n  using driver `GPKG'\nSimple feature collection with 112216 features and 26 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 352183.3 ymin: -1254631 xmax: 364874.4 ymax: -1240066\nProjected CRS: WGS 84 / Antarctic Polar Stereographic",
    "crumbs": [
      "Notebooks",
      "Estimating a hiking function"
    ]
  },
  {
    "objectID": "notebooks/03-estimating-a-hiking-function.html#now-look-at-the-slope-speed-plots",
    "href": "notebooks/03-estimating-a-hiking-function.html#now-look-at-the-slope-speed-plots",
    "title": "Estimating a hiking function",
    "section": "Now look at the slope-speed plots",
    "text": "Now look at the slope-speed plots\nIf we first make a crude estimate using geom_smooth on all the data we can start to appreciate the challenge\n\nggplot(all_traces, aes(x = slope_h, y = speed_km_h)) +\n  geom_point(alpha = 0.25, size = 0.5) +\n  geom_smooth() + \n  theme_minimal()\n\n\n\n\n\n\n\n\nWhile the result is somewhat bell-shaped as we might hope, there are a lot of fixes that seem unlikely to be related to movement from place to place, rather they are ‘milling about’ in place - such as at basecamp, at experiment sites, at rest stops, etc.\nWe can of course fit a curve of desired functional form. In the relevant literature, there are essentially two functional forms, exponential, in Waldo Tobler’s original formulation1, given by \\[\nv=6e^{-3.5\\|{s+0.05}\\|}\n\\] which gives hiking speed \\(v\\) in km/h for a slope (given as rise over run) \\(s\\). This function has subsequently modified by others.2\nOther work3 yields speeds essentially Gaussian with respect to slope centred at slight downward slopes, i.e.\n\\[\nv = ae^{-b(s+c)^2}\n\\]\nWe can explicitly fit such functional forms to the data using the nlsLM function from the minpack.lm package:\n\n# Tobler-like\nmod_tobler &lt;- nlsLM(speed_km_h ~ a * exp(-b * abs(slope_h + c)), data = all_traces,\n                    start = c(a = 5, b = 3, c = 0.05))\n# Gaussian\nmod_gauss &lt;- nlsLM(speed_km_h ~ a * dnorm(slope_h, m, s), data = all_traces,\n                   start = c(a = 5, m = 0, s = 0.5))\n# Student's t (for heavier tails)\nmod_students_t &lt;- nlsLM(speed_km_h ~ a * dt((slope_h + m), d), data = all_traces,\n                   start = c(a = 5, m = 0, d = 0.001))\n\nNote that we use the probability density functions dnorm and dt here for convenience of parameterisation. It is easier to revert to base R plotting to get a feel for what these look like:\n\n# a non spatial version of the data for plotting - which it is convenient to \ngps_data &lt;- all_traces |&gt;\n  st_drop_geometry() |&gt;\n  select(slope_h, speed_km_h)\n\ns &lt;- -200:200 / 100\nslopes &lt;- data.frame(slope_h = s)\nplot(gps_data, col = \"lightgray\", cex = 0.5)\nlines(s, predict(mod_tobler, slopes), col = \"red\", lwd = 2)\nlines(s, predict(mod_gauss, slopes), col = \"blue\", lwd = 2)\nlines(s, predict(mod_students_t, slopes), col = \"forestgreen\", lwd = 2)\nlegend(\"topright\", legend = c(\"Tobler\", \"Gaussian\", \"Student's t\"), \n       col = c(\"red\", \"blue\", \"forestgreen\"), lwd = 2, lty = 1)\n\n\n\n\n\n\n\n\nThat’s the process… but we need to apply it to filtered data to get closer to a reasonable outcome. Wrap the model-building in convenience functions:\n\nget_tobler_hiking_function &lt;- function(df) {\n  nlsLM(speed_km_h ~ a * exp(-b * abs(slope_h + c)), data = df,\n        start = c(a = 5, b = 3, c = 0.05))  \n}\n\nget_gaussian_hiking_function &lt;- function(df) {\n  nlsLM(speed_km_h ~ a * dnorm(slope_h, m, s), data = df,\n        start = c(a = 5, m = 0, s = 0.5))\n}\n\nget_students_t_hiking_function &lt;- function(df) {\n  nlsLM(speed_km_h ~ a * dt((slope_h + m), d), data = df,\n        start = c(a = 5, m = 0, d = 0.001))\n}",
    "crumbs": [
      "Notebooks",
      "Estimating a hiking function"
    ]
  },
  {
    "objectID": "notebooks/03-estimating-a-hiking-function.html#cleaning-the-data-to-get-a-better-hiking-function",
    "href": "notebooks/03-estimating-a-hiking-function.html#cleaning-the-data-to-get-a-better-hiking-function",
    "title": "Estimating a hiking function",
    "section": "Cleaning the data to get a better hiking function",
    "text": "Cleaning the data to get a better hiking function\nThere are a number of features in the data that might allow us to exclude such data from consideration. We examine three below:\n\nOnly consider an ‘upper bound’ on the distribution, say the 90th percentile of speed_km_h relative to a given slope\nRemove fixes where the density of fixes is high since these may relate to base camp sites, etc.\nRemove fixes with high turn angles, since these may relate to where the data suggest a lot of ‘milling about’\n\nWe look at each of these below.\n\nUpper bound of the distribution\nIf we only consider speed estimates at or close to the upper bound of the data, then we are removing all the milling about data:\n\nd90 &lt;- gps_data |&gt;\n  mutate(slope_h = round(slope_h, 2)) |&gt;\n  group_by(slope_h) |&gt;\n  summarise(speed_km_h = quantile(speed_km_h, 0.9)) |&gt;\n  ungroup()\n\nmod_tobler &lt;- get_tobler_hiking_function(d90)\nmod_gauss &lt;- get_gaussian_hiking_function(d90)\nmod_students_t &lt;- get_students_t_hiking_function(d90)\n\nplot(gps_data, col = \"lightgray\", cex = 0.5,\n     main = \"Hiking functions from 90th percentile speeds\")\npoints(d90, cex = 0.5) \nlines(s, predict(mod_tobler, slopes), col = \"red\", lwd = 2)\nlines(s, predict(mod_gauss, slopes), col = \"blue\", lwd = 2)\nlines(s, predict(mod_students_t, slopes), col = \"forestgreen\", lwd = 2)\nlegend(\"topright\", legend = c(\"Tobler\", \"Gaussian\", \"Student's t\"), \n       col = c(\"red\", \"blue\", \"forestgreen\"), lwd = 2, lty = 1)\n\n\n\n\n\n\n\n\nBased on residual sum-of-squares, the Tobler-like function is the best fit in this case (although the differences are small). In this particular case, the paramterisation is strikingly similar to Tobler’s\n\nsummary(mod_tobler)\n\n\nFormula: speed_km_h ~ a * exp(-b * abs(slope_h + c))\n\nParameters:\n  Estimate Std. Error t value Pr(&gt;|t|)    \na 5.950260   0.141452  42.065  &lt; 2e-16 ***\nb 3.399181   0.114934  29.575  &lt; 2e-16 ***\nc 0.014756   0.004926   2.995  0.00302 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5403 on 249 degrees of freedom\n\nNumber of iterations to convergence: 4 \nAchieved convergence tolerance: 1.49e-08\n\n\nGiving us \\(v = 5.95e^{-3.39\\|s+0.0147\\|}\\), which only differs much from Tobler’s proposed formula by the offset from 0 slope, which is reduced from 0.05 to 0.0147.\nNote that by choosing a different quantile than the 90th percentile we can vary the speeds predicted by a model produced in this way.\n\n\nFiltering by densely travelled locations\nTODO: Add number of distinct individuals to the binned data as an additional potential filter.\nThe idea here is that densely travelled locations are near base camps and similar sites, and not where scientists are ‘on the move’. The approach below uses hex binning to find densely trafficked areas and exclude fixes in those areas.\n\nhexes &lt;- all_traces |&gt;\n  st_make_grid(cellsize = 60, square = FALSE, what = \"polygons\") |&gt;\n  st_as_sf(crs = st_crs(all_traces))\n\ncounts &lt;- hexes |&gt;\n  st_intersects(all_traces) |&gt;\n  lengths()\n\nhexes &lt;- hexes |&gt;\n  mutate(n = counts) |&gt;\n  filter(n &gt; 0)\n\nMap with tmap (greater flexibility on the classification scheme)\n\ntm_shape(hexes) +\n  tm_fill(col = \"n\", style = \"quantile\", n = 20, palette = \"-magma\") +\n  tm_layout(legend.outside = TRUE)\n\n\n\n\n\n\n\n\nBut where to cut off the data? Here’s a histogram… although we need to cut out the really big numbers to see anything…\n\nhexes |&gt; filter(n &lt; 50) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = n), fill = \"grey\", colour = \"black\", linewidth = 0.35) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis doesn’t really help… but it does suggest that perhaps somewhere around 25?\nHowever… it’s not entirely clear that this yields better results!\n\nd_hexes &lt;- all_traces |&gt;\n  st_join(hexes) |&gt; \n  filter(n &lt; 25) |&gt;\n  st_drop_geometry() |&gt;\n  select(slope_h, speed_km_h)\n\nmod_tobler &lt;- get_tobler_hiking_function(d_hexes)\nmod_gauss &lt;- get_gaussian_hiking_function(d_hexes)\nmod_students_t &lt;- get_students_t_hiking_function(d_hexes)\n\nplot(gps_data, col = \"lightgray\", cex = 0.5,\n     main = \"Hiking functions from less densely trafficked areas\")\npoints(d_hexes, cex = 0.5) \nlines(s, predict(mod_tobler, slopes), col = \"red\", lwd = 2)\nlines(s, predict(mod_gauss, slopes), col = \"blue\", lwd = 2)\nlines(s, predict(mod_students_t, slopes), col = \"forestgreen\", lwd = 2)\nlegend(\"topright\", legend = c(\"Tobler\", \"Gaussian\", \"Student's t\"), \n       col = c(\"red\", \"blue\", \"forestgreen\"), lwd = 2, lty = 1)\n\n\n\n\n\n\n\n\n\n\nRemoving fixes with large turn angles\nAgain, this is a way to potentially remove data where there is a lot of milling about. As with the density approach, it’s hard to know what is a sensible cutoff. A map of the fixes coloured by turn angle is not necessarily much help:\n\nggplot(all_traces) +\n  geom_sf(aes(colour = turn_angle), size = 0.25)\n\n\n\n\n\n\n\n\nIn fact it seems that a rather aggressive seeming filter is needed before base camp and similar areas ‘show through’:\n\nggplot(all_traces |&gt; filter(turn_angle &lt; 5)) +\n  geom_sf(size = 0.2)\n\n\n\n\n\n\n\n\n\nd_low_turn_angle &lt;- all_traces |&gt;\n  filter(turn_angle &lt; 5) |&gt;\n  st_drop_geometry() |&gt;\n  select(slope_h, speed_km_h)\n\nmod_tobler &lt;- get_tobler_hiking_function(d_low_turn_angle)\nmod_gauss &lt;- get_gaussian_hiking_function(d_low_turn_angle)\nmod_students_t &lt;- get_students_t_hiking_function(d_low_turn_angle)\n\nplot(gps_data, col = \"lightgray\", cex = 0.5,\n     main = \"Hiking functions from fixes with low turn angles\")\npoints(d_low_turn_angle, cex = 0.5) \nlines(s, predict(mod_tobler, slopes), col = \"red\", lwd = 2)\nlines(s, predict(mod_gauss, slopes), col = \"blue\", lwd = 2)\nlines(s, predict(mod_students_t, slopes), col = \"forestgreen\", lwd = 2)\nlegend(\"topright\", legend = c(\"Tobler\", \"Gaussian\", \"Student's t\"), \n       col = c(\"red\", \"blue\", \"forestgreen\"), lwd = 2, lty = 1)",
    "crumbs": [
      "Notebooks",
      "Estimating a hiking function"
    ]
  },
  {
    "objectID": "notebooks/03-estimating-a-hiking-function.html#conclusion",
    "href": "notebooks/03-estimating-a-hiking-function.html#conclusion",
    "title": "Estimating a hiking function",
    "section": "Conclusion",
    "text": "Conclusion\nThis is still a work in progress…",
    "crumbs": [
      "Notebooks",
      "Estimating a hiking function"
    ]
  },
  {
    "objectID": "notebooks/03-estimating-a-hiking-function.html#footnotes",
    "href": "notebooks/03-estimating-a-hiking-function.html#footnotes",
    "title": "Estimating a hiking function",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTobler WR. 1993. Three Presentations on Geographical Analysis and Modeling: Non-Isotropic Geographic Modeling; Speculations on the Geometry of Geography; and Global Spatial Analysis. Technical Report 93–1. NCGIA Technical Reports. Santa Barbara, CA: National Center for Geographic Information and Analysis.↩︎\nSee, for example, Márquez-Pérez J, I Vallejo-Villalta and JI Álvarez-Francoso. 2017. Estimated travel time for walking trails in natural areas. Geografisk Tidsskrift-Danish Journal of Geography 117(1) 53–62. doi: 10.1080/00167223.2017.1316212↩︎\nIrmischer IJ and KC Clarke. 2018. Measuring and modeling the speed of human navigation. Cartography and Geographic Information Science 45(2). 177–186. doi: 10.1080/15230406.2017.1292150↩︎",
    "crumbs": [
      "Notebooks",
      "Estimating a hiking function"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Science impacts on Antarctica",
    "section": "",
    "text": "A simple website to share ongoing project work on possible impacts of science in Antarctica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverview / plan\n\n\nAntarctica Dry Valleys vulnerability to human impacts\n\n\n\n\n\n\n\n\nJul 18, 2024\n\n\nDavid O’Sullivan\n\n\n\n\n\n\n\n\n\n\n\n\nExploring GPS data\n\n\nChecking over GPS data for accuracy of speed, etc.\n\n\n\n\n\n\n\n\nJul 16, 2024\n\n\nDavid O’Sullivan\n\n\n\n\n\n\n\n\n\n\n\n\nCleaning GPS data\n\n\nAssembling provided GPS data into cleaned files, and a single large dataset\n\n\n\n\n\n\n\n\nJul 17, 2024\n\n\nDavid O’Sullivan\n\n\n\n\n\n\n\n\n\n\n\n\nEstimating a hiking function\n\n\nA work in progress…\n\n\n\n\n\n\n\n\nJul 17, 2024\n\n\nDavid O’Sullivan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebooks/00-notes.html",
    "href": "notebooks/00-notes.html",
    "title": "Overview / plan",
    "section": "",
    "text": "Update History\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges\n\n\n\n\n2024-07-18\nReprioritised items.\n\n\n2024-07-18\nInitial post.\n\n\n\n\n\n\nWill keep this page updated as we go.\n\nLocalised hiking functions – working on this\n\nDerive from the GPS data\n\nMake a hiking network – can do this in principle, but resolution to be agreed, and landcover costs determined\n\nUse Tobler function for now (see 5. below for more).\nNetwork to be based on hexagonal grid of points, not raster (put this functionality in the R function script, i.e. generate the hex array in R, not Q or an external tool)\nCover types important - can we assume all the same? Apart from obvious ice?\n\nSelect a set of central places\n\nbased on GPS data counts (ask if this is representative, or are there more?)\n\nModify igraph betweenness centrality methods to operate on a limited set of ODs:\n\nThis might require iterating over OD pairs to get single shortest paths as lists of vertices/edges, then summing the # appearances of each across all trips\nGenerate for all pairs within some time range of one another only (assume that people will take known routes via closer central places)\n\nOutput graphs as hex (vertex) and line (edge) spatial datasets for visualization\n\nhow well do these match the GPS data?",
    "crumbs": [
      "Notebooks",
      "Overview / plan"
    ]
  },
  {
    "objectID": "notebooks/01-exploring-gps-data.html",
    "href": "notebooks/01-exploring-gps-data.html",
    "title": "Exploring GPS data",
    "section": "",
    "text": "Update History\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nChanges\n\n\n\n\n2024-07-19\nUpdated to add turn angle calculation and source gps cleaning function from gps-data-util.R.\n\n\n2024-07-16\nInitial post.\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(janitor)\nlibrary(stringr)\nlibrary(here)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(terra)\nlibrary(tmap)\nlibrary(ggplot2)\nlibrary(zoo) # useful for serial data\nlibrary(R.utils)\n\nsource(str_glue(\"{here()}/scripts/gps-data-utils.R\"))\nThese notes explore the usefulness, accuracy etc. of the provided GPS data.\nOf particular interest is the asymmetry or not of movement speeds with respect to slope, given the salience of this for ‘hiking functions’. It is possible in a largely ‘unpathed’ environment that the asymmetry is limited (see e.g. Rees 20041)\nWe use just one of the datasets to explore general characteristics. Remove a meaningless column x and do a little bit of cleanup on the rcr and date and time columns.\ngps_data &lt;- get_gps_data_as_sf(str_glue(\n  \"{here()}/_data/GPS-1516Season-MiersValley/Fraser-FINAL.csv\")) |&gt;\n    select(-x) |&gt;\n    mutate(rcr = as.logical(rcr),\n           date_time = ymd_hms(paste(date, time)))",
    "crumbs": [
      "Notebooks",
      "Exploring GPS data"
    ]
  },
  {
    "objectID": "notebooks/01-exploring-gps-data.html#exploration-of-the-data",
    "href": "notebooks/01-exploring-gps-data.html#exploration-of-the-data",
    "title": "Exploring GPS data",
    "section": "Exploration of the data",
    "text": "Exploration of the data\nA summary of the data suggests that there are some data rows that should be ignored.\n\nsummary(gps_data)\n\n     index        rcr              date               time          \n Min.   :   1   Mode:logical   Length:7323        Length:7323       \n 1st Qu.:1832   TRUE:7304      Class :character   Class :character  \n Median :3662   NA's:19        Mode  :character   Mode  :character  \n Mean   :3662                                                       \n 3rd Qu.:5492                                                       \n Max.   :7323                                                       \n    valid              latitude          n_s              longitude    \n Length:7323        Min.   :-78.12   Length:7323        Min.   :163.7  \n Class :character   1st Qu.:-78.11   Class :character   1st Qu.:163.8  \n Mode  :character   Median :-78.10   Mode  :character   Median :163.8  \n                    Mean   :-78.10                      Mean   :163.9  \n                    3rd Qu.:-78.10                      3rd Qu.:163.9  \n                    Max.   :-78.09                      Max.   :164.2  \n     e_w               height_m       speed_km_h           pdop      \n Length:7323        Min.   :-23.1   Min.   :  0.000   Min.   : 0.98  \n Class :character   1st Qu.:102.1   1st Qu.:  0.255   1st Qu.: 1.14  \n Mode  :character   Median :110.8   Median :  0.496   Median : 1.19  \n                    Mean   :180.1   Mean   :  1.604   Mean   : 1.27  \n                    3rd Qu.:165.7   3rd Qu.:  2.241   3rd Qu.: 1.24  \n                    Max.   :636.9   Max.   :209.555   Max.   :13.76  \n      hdop              vdop        nsat_used_view       distance_m      \n Min.   : 0.6100   Min.   :0.7600   Length:7323        Min.   :    0.00  \n 1st Qu.: 0.7400   1st Qu.:0.8600   Class :character   1st Qu.:    1.38  \n Median : 0.7900   Median :0.8900   Mode  :character   Median :    2.78  \n Mean   : 0.7977   Mean   :0.9756                      Mean   :   21.73  \n 3rd Qu.: 0.8400   3rd Qu.:0.9200                      3rd Qu.:   14.99  \n Max.   :13.7200   Max.   :4.7100                      Max.   :74486.45  \n          geometry      date_time                     \n POINT        :7323   Min.   :2016-01-13 16:28:31.07  \n epsg:3031    :   0   1st Qu.:2016-01-15 16:43:27.00  \n +proj=ster...:   0   Median :2016-01-19 12:46:32.00  \n                      Mean   :2016-01-19 01:37:06.72  \n                      3rd Qu.:2016-01-22 08:39:45.00  \n                      Max.   :2016-01-23 15:16:47.00  \n\n\nA speed of &gt; 200km/h was clearly not achieved on foot! Similarly an elapsed distance between 1/30Hz fixes of 74km was not on foot either.\nThe GPS dilution of precision measures for horizontal and vertical position (hdop and vdop) are mostly within the ‘good’ range (&lt;1) with some outliers. The 3D positions (pdop) are not as good, but are also generally considered reliable (&lt;5). Inspection of a quick map of the data suggests helicopter movement or similar for some ‘singleton’ isolated observations:\n\nggplot(gps_data) +\n  geom_sf(size = 0.25) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis being the case it seems reasonable to remove observations with clearly unreasonable speed estimates, assuming that these result from use of other forms of transport. However, before doing so, we augment the data with additional estimates of speed, distance, turn angle, etc. calculated from consecutive fixes (it is not advisable to remove any fixes before making these estimates).",
    "crumbs": [
      "Notebooks",
      "Exploring GPS data"
    ]
  },
  {
    "objectID": "notebooks/01-exploring-gps-data.html#sanity-checking-the-gps-estimates-of-speed-distance-and-height",
    "href": "notebooks/01-exploring-gps-data.html#sanity-checking-the-gps-estimates-of-speed-distance-and-height",
    "title": "Exploring GPS data",
    "section": "Sanity checking the GPS estimates of speed, distance, and height",
    "text": "Sanity checking the GPS estimates of speed, distance, and height\nBefore applying that potentially simplistic cleaning of the data, it is also reasonable to sanity check the speed, distance, and height estimates in the GPS data. First we obtain height data from a 10m DEM.\n\nxy &lt;- gps_data |&gt;\n  st_coordinates() |&gt;\n  as_tibble()\n\ndem &lt;- rast(str_glue(\"{here()}/_data/input/dry-valleys-10m.tif\"))\n# and useful for later will be a hillshade\nslope &lt;- dem |&gt; terra::terrain(\"slope\", unit = \"radians\")\naspect &lt;- dem |&gt; terra::terrain(\"aspect\", unit = \"radians\")\nhillshade &lt;- shade(slope, aspect)\nTRI &lt;- dem |&gt; terra::terrain(\"TRI\")\n\nheights_from_dem &lt;- dem |&gt;\n  terra::extract(xy, method = \"simple\") |&gt;\n  select(2)\n\nslope_from_dem &lt;- slope |&gt;\n  terra::extract(xy, method = \"simple\") |&gt;\n  select(2)\n\nTRI_from_dem &lt;- TRI |&gt;\n  terra::extract(xy, method = \"simple\") |&gt;\n  select(2)\n\nxy &lt;- xy |&gt;\n  bind_cols(heights_from_dem) |&gt;\n  rename(Z = `dry-valleys-10m`) |&gt;\n  bind_cols(slope_from_dem) |&gt;\n  mutate(dem_slope = tan(slope)) |&gt;\n  select(-slope) |&gt;\n  bind_cols(TRI_from_dem)\n\ngps_data_plus &lt;- gps_data |&gt;\n  bind_cols(xy)\n\nNow calculate estimates of distance, change in elevation, and slope between observations, from these numbers and from the GPS data.\n\ngps_data_plus &lt;- gps_data_plus |&gt;\n  mutate(dx1 = as.numeric(diff(as.zoo(X), na.pad = TRUE)), \n         dy1 = as.numeric(diff(as.zoo(Y), na.pad = TRUE)),\n         dx2 = as.numeric(diff(as.zoo(X), lag = -1, na.pad = TRUE)),\n         dy2 = as.numeric(diff(as.zoo(Y), lag = -1, na.pad = TRUE)),\n         turn_angle = get_turn_angle(dx1, dy1, dx2, dy2),\n         dz = as.numeric(diff(as.zoo(Z), na.pad = TRUE)),\n         dh = as.numeric(diff(as.zoo(height_m), na.pad = TRUE)),\n         dt = as.numeric(diff(as.zoo(date_time), na.pad = TRUE)),\n         dxy = sqrt(dx1^ 2 + dy1 ^ 2),\n         dxyz = sqrt(dx1 ^ 2 + dy1 ^ 2 + dz ^ 2),\n         dxyh = sqrt(distance_m ^ 2 + dh ^ 2),\n         slope_h = dh / distance_m,\n         slope_z = dz / dxy,\n         speedxy = dxy / dt * 3600 / 1000, speedxyz = dxyz / dt * 3600 / 1000) \n\nNow some comparisons.\n\nDistance estimates\nThe distance_m estimates in the provided data are a little higher than the manually calculated point to point straight line distances between fixes. However, examination of sequences of data show the two time series are well aligned (below). Differences may be due to filtering applied by the GPS unit, although this is not well documented.\nIn any case, the GPS distance_m variable seems safe for use in further analysis.\n\ngps_data_plus |&gt; \n  filter(dt == 30) |&gt;\n  slice(2:151) |&gt;\n  pivot_longer(cols = c(distance_m, dxy, dxyz)) |&gt;\n  ggplot() + \n  geom_line(aes(x = date_time, y = value, colour = name, group = name), alpha = 0.5) +\n  xlab(\"Date/time\") + ylab(\"Estimated distance\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nSpeed estimates\nDifferences in the speed estimates are more pronounced:\n\ngps_data_plus |&gt; \n  filter(dt == 30) |&gt;\n  slice(2:151) |&gt;\n  pivot_longer(cols = c(speed_km_h, speedxy, speedxyz)) |&gt;\n  ggplot() + \n  geom_line(aes(x = date_time, y = value, colour = name, group = name), alpha = 0.5) +\n  xlab(\"Date/time\") + ylab(\"Estimated speed\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe provided speed estimates are generally higher although there is some alignment between the time series, insofar as extended periods of low speeds tend to line up.\nA likely reason for the differences is that in a 30 second period (the usual interval between fixes) an individual may move in many directions so that the direct point to point distance between fixes is less than might be expected based on the recorded speed. So, for example, in the above chart between 16:30 and 16:40 the person was moving not in straight lines, where in the following 10 minutes they were moving in relatively straight lines. We can test this theory, at least qualitatively, by calculating a sinuosity estimate between fixes.\n\nsinuosity &lt;- gps_data_plus |&gt;\n  filter(dt == 30) |&gt;\n  slice(2:61) |&gt;\n  # select(date_time, speed_km_h, dxy, speedxy) |&gt;\n  mutate(sinuosity = speed_km_h / 120 / distance_m,\n         date_time_start = lag(date_time)) \n\nspeeds &lt;- sinuosity |&gt;\n  pivot_longer(cols = c(speed_km_h, speedxy))\n\nggplot(speeds) +\n  geom_step(aes(x = date_time, y = value, group = name, linetype = name), \n            direction = \"vh\", lwd = 0.5) +\n  geom_segment(data = sinuosity, \n               aes(x = date_time_start, xend = date_time, \n                   y = speed_km_h, colour = rank(sinuosity)), lwd = 2) +\n  scale_colour_distiller(palette = \"Reds\", direction = 1) +\n  xlab(\"Date/time\") + ylab(\"Estimated speed\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSince the estimated sinuosity here is based only on the GPS estimated speed and point to point distances, that it is generally highest when the difference between the GPS reported speed speed_km_h and the manually estimated speed speedxy is largest supports the assumption that the GPS is reporting speed using satellite carrier signal doppler effects.\nBased on this check, the GPS speed_km_h variable seems reasonable to use for hiking function estimation.\n\n\nGPS height and elevation from the DEM\nAgain, there are differences between heights recorded by the GPS units, and heights extracted from the 10m DEM. Again, it is difficult to know why these might occur, although there is a clear correlation between the two. There is no obvious correlation with surface roughness (TRI), for example, or with the vertical dilution of precision (vdop).\n\nggplot(gps_data_plus |&gt; \n         filter(dt == 30, distance_m &lt; 60, height_m &gt; 0, Z &gt; 0)) +\n  geom_point(aes(x = TRI, y = height_m / Z, colour = vdop), alpha = 0.25) +\n  scale_colour_viridis_c(option = \"A\", direction = -1) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nPragmatically, in the next section, I find that the relationship between slope and speed based on the GPS readings is much better behaved than that derived from the speed and elevation extracted from the DEM. The reason it can be used to estimate slope in that context is divergences between height_m (from the GPS) and Z (from the DEM) are serially correlated, so that estimates of slope derived from consecutive data points are useable for that purpose.\nSome reassurance that the GPS height estimates are suitably aligned is obtained by plotting each days set of observations of the two as time series. On days where much of the activity occurred at the same elevation or across a very limited elevation range there are obvious deviations, but these are relatively small in magnitude (a few metres); on days when more elevation chance is observed, the overall profile of the day’s activity matches well.\n\ngps_data_plus |&gt; \n  filter(dt == 30) |&gt;\n  pivot_longer(cols = c(height_m, Z)) |&gt;\n  ggplot() + \n  geom_line(aes(x = date_time, y = value, colour = name, group = name), alpha = 0.5) +\n  xlab(\"Date/time\") + ylab(\"Estimated elevation\") + \n  facet_wrap(~ date, scales = \"free\", ncol = 2) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAgain, it seems reasonable to use the GPS unit reported heights for estimation of hiking functions. The main impact on the analysis in the next section is to introduce noise into the slope at low values.",
    "crumbs": [
      "Notebooks",
      "Exploring GPS data"
    ]
  },
  {
    "objectID": "notebooks/01-exploring-gps-data.html#a-hiking-function",
    "href": "notebooks/01-exploring-gps-data.html#a-hiking-function",
    "title": "Exploring GPS data",
    "section": "A hiking function",
    "text": "A hiking function\nA hiking function relates slope of the land to speed at which it is traversed. Using the GPS unit reported speed and slope derived from GPS unit reported distance and height, locally estimated scatter plot smoothing yields an approximately Gaussian curve with the peak speed at or close to 0 slope. This gives some confidence that we can use these data to estimate hiking functions. The approach implied in this plot is insufficient, as the data contain many fixes that don’t give much information about ‘hiking’ as such. The preponderance of lower turn angle fixes in the more ‘mobile’ parts of the data (i.e. higher speeds) suggests that it may be possible to filter out those data points.\nBetter estimation of a hiking function is left to a later notebook (see Estimating a hiking function).\n\ngps_data_plus |&gt;\n  # here's a possible filter to apply to the data to improve the estimation\n  filter(dt == 30, speed_km_h &lt; 10, !is.na(slope_h), distance_m &gt; 2.5, turn_angle &lt; 150) |&gt;\n  ggplot(aes(x = slope_h, y = speed_km_h, colour = turn_angle)) +\n  geom_point(size = 0.25) +\n  geom_smooth(aes(x = slope_h, y = speed_km_h))\n\n\n\n\n\n\n\nmodel &lt;- loess(speed_km_h ~ slope_h, data = gps_data_plus)\n\nMany data in the above plot are probably from ‘milling about’ in breaks, at camp, or around experiments, rather than while on the move. The best way to remove these sections is probably based on turn angles.",
    "crumbs": [
      "Notebooks",
      "Exploring GPS data"
    ]
  },
  {
    "objectID": "notebooks/01-exploring-gps-data.html#conclusion-a-reasonable-gps-file-cleaning-function",
    "href": "notebooks/01-exploring-gps-data.html#conclusion-a-reasonable-gps-file-cleaning-function",
    "title": "Exploring GPS data",
    "section": "Conclusion: a reasonable GPS file cleaning function",
    "text": "Conclusion: a reasonable GPS file cleaning function\nBased on this exploration, GPS data need to be processed as follows (note that no initial conversion to a spatial format is required at this stage, since none of the added spatial data introduced above is required).\n\nRead raw data from CSV.\nClean names with janitor::clean_names.\nRemove meaningless variable x.\nAdd a name reflecting the id of the person whose data is.\nAugment data with dt (time interval between fixes), dh (height change between fixes), slope_h (estimated slope between fixes), and turn_angle (change in direction at this fix).\nRemove data outside expected latitudinal range (&gt; -78 latitude).\nRemove fixes with high estimated speeds (&gt;~ 10km/h).\nRemove fixes with long estimated distances (&gt;~ 60m).\nIdentify breaks in the series where dt != 30 and tag subsets of the data accordingly.\nCount number of fixes in each subset – consider removing small ones…\nDrop NAs and any rows where dt != 30.\n\nThis is the basis for a function get_cleaned_gps_data() in the script gps-data-utils.R used for cleaning up / augmenting the raw CSV files.",
    "crumbs": [
      "Notebooks",
      "Exploring GPS data"
    ]
  },
  {
    "objectID": "notebooks/01-exploring-gps-data.html#footnotes",
    "href": "notebooks/01-exploring-gps-data.html#footnotes",
    "title": "Exploring GPS data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRees WG. 2004. Least-cost paths in mountainous terrain. Computers & Geosciences 30(3) 203–209. doi: 10.1016/j.cageo.2003.11.001.↩︎",
    "crumbs": [
      "Notebooks",
      "Exploring GPS data"
    ]
  }
]